{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "ZHyZGVfPPTTk"
      },
      "outputs": [],
      "source": [
        "#!pip install pandasql\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark in Google Colab\n",
        "#!pip install pyspark\n",
        "\n",
        "# Importing SparkSession from pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_date, col, year\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "        .appName(\"Case_study_data_analysis\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "# Sample data for customers_df\n",
        "data_customers = [\n",
        "    ('123456ABCDE', '1055879', \"Trina's Trinkets\", 768),\n",
        "    ('123456ABCDE', '1045797', \"Trina's Trinkets\", 768),\n",
        "    ('123456ABCDE', '2340978', \"Trina's Trinkets\", 768),\n",
        "    ('78910FGHIJK', '3458978', \"Ben's Bikes\", 9714),\n",
        "    ('24680LMNOP', '989034', \"Georgia's Games\", 120),\n",
        "    ('78910FGHIJK', '349789', \"Ben's Bikes\", 9714)\n",
        "]\n",
        "\n",
        "# Define the schema for customers\n",
        "schema_customers = [\"crm_account_id\", \"instance_account_id\", \"account_name\", \"crm_total_arr\"]\n",
        "\n",
        "# Create a DataFrame for customers\n",
        "customers_df = spark.createDataFrame(data_customers, schema=schema_customers)\n",
        "\n",
        "# Sample data for tickets_df\n",
        "data_tickets = [\n",
        "    ('123456ABCDE', '349789', '10493689', '2022-06-15', '2022-07-15'),\n",
        "    ('24680LMNOP', '989034', '10422559', '2022-05-24', '2022-05-27'),\n",
        "    ('24680LMNOP', '989034', '10754554', '2022-08-29', '2022-08-29'),\n",
        "    ('123456ABCDE', '1045797', '11885092', '2023-09-06', '2023-09-07'),\n",
        "    ('123456ABCDE', '2340978', '11880840', '2023-09-05', '2023-09-12'),\n",
        "    ('78910FGHIJK', '3458978', '11834958', '2023-08-21', '2023-08-30')\n",
        "]\n",
        "\n",
        "# Define the schema for tickets\n",
        "schema_tickets = [\"crm_account_id\", \"instance_account_id\", \"ticket_id\", \"created_at\", \"solved_at\"]\n",
        "\n",
        "# Create a DataFrame for tickets\n",
        "tickets_df = spark.createDataFrame(data_tickets, schema_tickets)\n",
        "\n",
        "# Convert the created_at and solved_at columns to date type\n",
        "tickets_df = tickets_df.withColumn(\"created_at\", to_date(col(\"created_at\"))) \\\n",
        "                       .withColumn(\"solved_at\", to_date(col(\"solved_at\")))\n",
        "\n",
        "# Register the DataFrames as temp views\n",
        "customers_df.createOrReplaceTempView(\"customers\")\n",
        "tickets_df.createOrReplaceTempView(\"tickets\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o3JHODtHPa7Z"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.-How many unique customers are in the Customers table? (Customers are defined at the crm level, not the instance level)##"
      ],
      "metadata": {
        "id": "cCDgojwQi3Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_unique_customers = spark.sql(\"\"\"\n",
        "SELECT COUNT(DISTINCT crm_account_id) AS unique_customers\n",
        "FROM Customers\"\"\")\n",
        "number_of_unique_customers.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02RdwnrZdOPr",
        "outputId": "a560db35-78a7-422c-bbbb-4e599a321acc"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|unique_customers|\n",
            "+----------------+\n",
            "|               3|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.- What are 2 ways to identify which customer has the highest ARR? (the ARR field is crm_total_arr)##"
      ],
      "metadata": {
        "id": "vrL7RAguhBml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##  Method 1\n",
        "highest_ARR_method_1 = spark.sql(\"\"\"\n",
        "SELECT crm_account_id, account_name, crm_total_arr\n",
        "FROM Customers\n",
        "ORDER BY crm_total_arr DESC\n",
        "LIMIT 1\n",
        "\"\"\")\n",
        "highest_ARR_method_1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_vhR7UXf4hu",
        "outputId": "a9aea8cb-1b80-43e4-b640-fcbf6630f5f7"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+-------------+\n",
            "|crm_account_id|account_name|crm_total_arr|\n",
            "+--------------+------------+-------------+\n",
            "|   78910FGHIJK| Ben's Bikes|         9714|\n",
            "+--------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Method 2\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Assuming 'customers_df' is your DataFrame\n",
        "highest_ARR_method = customers_df.orderBy(F.col(\"crm_total_arr\").desc()).limit(1)\n",
        "\n",
        "highest_ARR_method.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su06Z1HhhK_q",
        "outputId": "c43cc971-5a98-4aa3-f422-91eb5902342b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------------+------------+-------------+\n",
            "|crm_account_id|instance_account_id|account_name|crm_total_arr|\n",
            "+--------------+-------------------+------------+-------------+\n",
            "|   78910FGHIJK|            3458978| Ben's Bikes|         9714|\n",
            "+--------------+-------------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.- Create a column called \"ARR bands\" using the crm_total_arr field and calculate how many unique crm_account_id's fall into each band.##"
      ],
      "metadata": {
        "id": "UcAwqn6dm2GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARR_bands = spark.sql(\"\"\"\n",
        "WITH ARR_Bands AS (\n",
        "  SELECT\n",
        "    crm_account_id,\n",
        "    CASE\n",
        "      WHEN crm_total_arr >= 250000 THEN '>$250K'\n",
        "      WHEN crm_total_arr >= 100000 THEN '$100K-$250K'\n",
        "      WHEN crm_total_arr >= 10000 THEN '$10K-$100K'\n",
        "      ELSE '<$10K'\n",
        "    END AS arr_band\n",
        "  FROM Customers\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  arr_band,\n",
        "  COUNT(DISTINCT crm_account_id) AS unique_customers\n",
        "FROM ARR_Bands\n",
        "GROUP BY arr_band\n",
        "ORDER BY arr_band;\n",
        "\"\"\")\n",
        "ARR_bands.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg114Ajim4L9",
        "outputId": "7151949a-66c3-48ac-b00b-6efb205f7f7f"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------+\n",
            "|arr_band|unique_customers|\n",
            "+--------+----------------+\n",
            "|   <$10K|               3|\n",
            "+--------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhaps threshold to segment customers in different bins could be set to: 100, 500 and 1000 in this way customers would be mapped in different categories"
      ],
      "metadata": {
        "id": "yH3uewspnFuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARR_bands = spark.sql(\"\"\"\n",
        "WITH ARR_Bands AS (\n",
        "  SELECT\n",
        "    crm_account_id,\n",
        "    CASE\n",
        "      WHEN crm_total_arr >= 1000 THEN '>$1000'\n",
        "      WHEN crm_total_arr >= 500 THEN '$500-$1000'\n",
        "      WHEN crm_total_arr >= 100 THEN '$100-$500'\n",
        "      ELSE '<$100'\n",
        "    END AS arr_band\n",
        "  FROM Customers\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  arr_band,\n",
        "  COUNT(DISTINCT crm_account_id) AS unique_customers\n",
        "FROM ARR_Bands\n",
        "GROUP BY arr_band\n",
        "ORDER BY arr_band;\n",
        "\"\"\")\n",
        "ARR_bands.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLppu1lrnDOG",
        "outputId": "6789ff57-142c-4087-e986-04b38671a1af"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+\n",
            "|  arr_band|unique_customers|\n",
            "+----------+----------------+\n",
            "| $100-$500|               1|\n",
            "|$500-$1000|               1|\n",
            "|    >$1000|               1|\n",
            "+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.-How many tickets were submitted in each month of 2023?##"
      ],
      "metadata": {
        "id": "svVPbEcpn2DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tickets_per_month = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  EXTRACT(YEAR FROM created_at) AS year,\n",
        "  EXTRACT(MONTH FROM created_at) AS month,\n",
        "  COUNT(ticket_id) AS tickets_submitted\n",
        "FROM Tickets\n",
        "WHERE EXTRACT(YEAR FROM created_at) = 2023\n",
        "GROUP BY year, month\n",
        "ORDER BY month;\n",
        "\"\"\")\n",
        "tickets_per_month.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS7eKq4jnl_w",
        "outputId": "45da8b1c-e65e-46f9-fa93-68125a29b867"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----------------+\n",
            "|year|month|tickets_submitted|\n",
            "+----+-----+-----------------+\n",
            "|2023|    8|                1|\n",
            "|2023|    9|                2|\n",
            "+----+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.- What was the average number of days to solve a ticket for tickets created any time in 2023?  For this question, assume all tickets in the table have been solved (i.e. have a valid solved_at populated).##"
      ],
      "metadata": {
        "id": "OKWpk8sMoE-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average number of days to solve a ticket in 2023:\n",
        "avg_days_to_solve = spark.sql(\"\"\"\n",
        "SELECT AVG(DATEDIFF(solved_at, created_at)) as avg_days_to_solve\n",
        "FROM tickets\n",
        "WHERE YEAR(created_at) = 2023\n",
        "\"\"\")\n",
        "\n",
        "avg_days_to_solve.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T6UjIJUoEWR",
        "outputId": "11bad219-cb8c-4d0d-f822-0f88383be21d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|avg_days_to_solve|\n",
            "+-----------------+\n",
            "|5.666666666666667|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.- What is the count of unique tickets per customer for each month in 2023?##\n",
        "\n"
      ],
      "metadata": {
        "id": "PXR101uMo093"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can run the SQL query\n",
        "unique_tickets_per_customer = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  c.account_name,\n",
        "  EXTRACT(YEAR FROM t.created_at) AS year,\n",
        "  EXTRACT(MONTH FROM t.created_at) AS month,\n",
        "  COUNT(DISTINCT t.ticket_id) AS unique_ticket_count\n",
        "FROM Tickets t\n",
        "JOIN Customers c ON t.crm_account_id = c.crm_account_id\n",
        "WHERE EXTRACT(YEAR FROM t.created_at) = 2023\n",
        "GROUP BY c.account_name, year, month\n",
        "ORDER BY c.account_name, year, month;\n",
        "\"\"\")\n",
        "unique_tickets_per_customer.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qAGVvd0oApv",
        "outputId": "3e4b953d-27ac-4e9b-b74c-2407b1e2f3a2"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----+-----+-------------------+\n",
            "|    account_name|year|month|unique_ticket_count|\n",
            "+----------------+----+-----+-------------------+\n",
            "|     Ben's Bikes|2023|    8|                  1|\n",
            "|Trina's Trinkets|2023|    9|                  2|\n",
            "+----------------+----+-----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.- What percentage of customers submitted fewer than 5 tickets in July 2023?##"
      ],
      "metadata": {
        "id": "MvtR0x81rZZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Tickets per customer created on July 2023\n",
        "\n"
      ],
      "metadata": {
        "id": "ay3swGImu2UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query to count the number of tickets per customer for July 2023\n",
        "tickets_per_customer_july_query = \"\"\"\n",
        "SELECT\n",
        "  crm_account_id,\n",
        "  COUNT(ticket_id) AS ticket_count\n",
        "FROM tickets\n",
        "WHERE EXTRACT(YEAR FROM created_at) = 2023 AND EXTRACT(MONTH FROM created_at) = 7\n",
        "GROUP BY crm_account_id\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "tickets_per_customer_july = spark.sql(tickets_per_customer_july_query)\n",
        "\n",
        "# Show the result\n",
        "tickets_per_customer_july.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBzKBNdnrSVE",
        "outputId": "19e383ff-ddaa-468f-e7df-fc8114416f80"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+\n",
            "|crm_account_id|ticket_count|\n",
            "+--------------+------------+\n",
            "+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Customers with fewer than 5 tickets"
      ],
      "metadata": {
        "id": "xe_qsj4QwiI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers_fewer_than_5_tickets = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  crm_account_id,\n",
        "  COUNT(ticket_id) AS ticket_count\n",
        "FROM tickets\n",
        "WHERE EXTRACT(YEAR FROM created_at) = 2023\n",
        "  AND EXTRACT(MONTH FROM created_at) = 7\n",
        "GROUP BY crm_account_id\n",
        "HAVING COUNT(ticket_id) < 5\n",
        "\"\"\")\n",
        "\n",
        "customers_fewer_than_5_tickets.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyj0xzOcv9uk",
        "outputId": "fe16aaae-23a8-4d99-d0d6-6a1dd7877f24"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+\n",
            "|crm_account_id|ticket_count|\n",
            "+--------------+------------+\n",
            "+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After calculating the amount of tickets per customer (Step 1) from the total amount of tickets per customer, filter those that have less than 5 tickets (step 2); then, divide those with 5 tickets (Step 2) by the tickets per customer (Step 1) to get the percentage of customers with fewer than 5 tickets"
      ],
      "metadata": {
        "id": "OqCkPRefwytg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Query to execute\n",
        "percentage_customers_fewer_than_5_tickets_query = \"\"\"\n",
        "WITH JulyTickets AS (\n",
        "  SELECT\n",
        "    crm_account_id,\n",
        "    COUNT(ticket_id) AS ticket_count\n",
        "  FROM tickets\n",
        "  WHERE EXTRACT(YEAR FROM created_at) = 2023 AND EXTRACT(MONTH FROM created_at) = 7\n",
        "  GROUP BY crm_account_id\n",
        "),\n",
        "CustomersWithFewerThan5Tickets AS (\n",
        "  SELECT\n",
        "    crm_account_id\n",
        "  FROM JulyTickets\n",
        "  WHERE ticket_count < 5\n",
        "),\n",
        "TotalCustomers AS (\n",
        "  SELECT\n",
        "    COUNT(DISTINCT crm_account_id) AS total_customers\n",
        "  FROM customers\n",
        "),\n",
        "CustomersWithFewerThan5TicketsCount AS (\n",
        "  SELECT\n",
        "    COUNT(crm_account_id) AS customers_with_fewer_than_5_tickets\n",
        "  FROM CustomersWithFewerThan5Tickets\n",
        ")\n",
        "SELECT\n",
        "  (customers_with_fewer_than_5_tickets / CAST(total_customers AS FLOAT)) * 100 AS percentage_customers_fewer_than_5_tickets\n",
        "FROM\n",
        "  CustomersWithFewerThan5TicketsCount,\n",
        "  TotalCustomers;\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "percentage_customers_fewer_than_5_tickets = spark.sql(percentage_customers_fewer_than_5_tickets_query)\n",
        "\n",
        "# Show the result\n",
        "percentage_customers_fewer_than_5_tickets.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm6leOtirN5M",
        "outputId": "50eb18a6-d3f6-464f-deb2-1375f1445fba"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------+\n",
            "|percentage_customers_fewer_than_5_tickets|\n",
            "+-----------------------------------------+\n",
            "|                                      0.0|\n",
            "+-----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have no data of tickets created in July, it makes sense that the response is 0.\n",
        "We should test this adding some lines with data from July. Let's do so:"
      ],
      "metadata": {
        "id": "Sl3yQTZBy_eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional sample data for tickets created in July 2023\n",
        "additional_data_tickets = [\n",
        "    ('123456ABCDE', '349789', '10500001', '2023-07-01', '2023-07-05'),\n",
        "    ('123456ABCDE', '349789', '10500002', '2023-08-01', '2023-08-10'),\n",
        "    ('78910FGHIJK', '3458978', '10500003', '2023-09-15', '2023-09-20'),\n",
        "    ('24680LMNOP', '989034', '10500004', '2023-06-20', '2023-06-25'),\n",
        "    ('78910FGHIJK', '349789', '10500005', '2023-09-28', '2023-09-30'),\n",
        "    ('24680LMNOP', '989034', '10500006', '2023-07-03', None)  # Assuming ticket is not solved yet\n",
        "]\n",
        "\n",
        "# Append the additional data to the existing data_tickets list\n",
        "data_tickets.extend(additional_data_tickets)\n",
        "\n",
        "# Recreate the tickets_df DataFrame with the new data\n",
        "tickets_df = spark.createDataFrame(data_tickets, schema_tickets)\n",
        "\n",
        "# Convert the 'created_at' and 'solved_at' columns to date type again\n",
        "tickets_df = tickets_df.withColumn(\"created_at\", to_date(col(\"created_at\"))) \\\n",
        "                       .withColumn(\"solved_at\", to_date(col(\"solved_at\")))\n",
        "\n",
        "# Register the updated DataFrame as a temp view\n",
        "tickets_df.createOrReplaceTempView(\"tickets\")\n"
      ],
      "metadata": {
        "id": "Y0FpRuCPzVCH"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query to execute\n",
        "percentage_customers_fewer_than_5_tickets_query = \"\"\"\n",
        "WITH JulyTickets AS (\n",
        "  SELECT\n",
        "    crm_account_id,\n",
        "    COUNT(ticket_id) AS ticket_count\n",
        "  FROM tickets\n",
        "  WHERE EXTRACT(YEAR FROM created_at) = 2023 AND EXTRACT(MONTH FROM created_at) = 7\n",
        "  GROUP BY crm_account_id\n",
        "),\n",
        "CustomersWithFewerThan5Tickets AS (\n",
        "  SELECT\n",
        "    crm_account_id\n",
        "  FROM JulyTickets\n",
        "  WHERE ticket_count < 5\n",
        "),\n",
        "TotalCustomers AS (\n",
        "  SELECT\n",
        "    COUNT(DISTINCT crm_account_id) AS total_customers\n",
        "  FROM customers\n",
        "),\n",
        "CustomersWithFewerThan5TicketsCount AS (\n",
        "  SELECT\n",
        "    COUNT(crm_account_id) AS customers_with_fewer_than_5_tickets\n",
        "  FROM CustomersWithFewerThan5Tickets\n",
        ")\n",
        "SELECT\n",
        "  (customers_with_fewer_than_5_tickets / CAST(total_customers AS FLOAT)) * 100 AS percentage_customers_fewer_than_5_tickets\n",
        "FROM\n",
        "  CustomersWithFewerThan5TicketsCount,\n",
        "  TotalCustomers;\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "percentage_customers_fewer_than_5_tickets = spark.sql(percentage_customers_fewer_than_5_tickets_query)\n",
        "\n",
        "# Show the result\n",
        "percentage_customers_fewer_than_5_tickets.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DSii_ab1BsL",
        "outputId": "e6e52732-7df0-4cc8-9ed6-8fa0f2f92bdc"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------+\n",
            "|percentage_customers_fewer_than_5_tickets|\n",
            "+-----------------------------------------+\n",
            "|                        66.66666666666666|\n",
            "+-----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query to count the number of tickets per customer for July 2023\n",
        "tickets_per_customer_july_query = \"\"\"\n",
        "SELECT\n",
        "  crm_account_id,\n",
        "  COUNT(ticket_id) AS ticket_count\n",
        "FROM tickets\n",
        "WHERE EXTRACT(YEAR FROM created_at) = 2023 AND EXTRACT(MONTH FROM created_at) = 7\n",
        "GROUP BY crm_account_id\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "tickets_per_customer_july = spark.sql(tickets_per_customer_july_query)\n",
        "\n",
        "# Show the result\n",
        "tickets_per_customer_july.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5wd16p615zj",
        "outputId": "b9804ebc-d241-4f6b-cfe3-0fddbbd8d825"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+\n",
            "|crm_account_id|ticket_count|\n",
            "+--------------+------------+\n",
            "|   123456ABCDE|           1|\n",
            "|    24680LMNOP|           1|\n",
            "+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers_fewer_than_5_tickets = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  crm_account_id,\n",
        "  COUNT(ticket_id) AS ticket_count\n",
        "FROM tickets\n",
        "WHERE EXTRACT(YEAR FROM created_at) = 2023\n",
        "  AND EXTRACT(MONTH FROM created_at) = 7\n",
        "GROUP BY crm_account_id\n",
        "HAVING COUNT(ticket_id) < 5\n",
        "\"\"\")\n",
        "\n",
        "customers_fewer_than_5_tickets.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTnhqy892MH9",
        "outputId": "c9c37a19-4208-4c7d-d56f-04bb18e5167c"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+\n",
            "|crm_account_id|ticket_count|\n",
            "+--------------+------------+\n",
            "|   123456ABCDE|           1|\n",
            "|    24680LMNOP|           1|\n",
            "+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After checking that 2 customers had fewer than 5 tickets in july; there were two customers in july; but there are 3 customers in our data base we can see that 2 divided by 3 makes sense."
      ],
      "metadata": {
        "id": "dkEF81qh1oS_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-krMtDak25x2"
      },
      "execution_count": 152,
      "outputs": []
    }
  ]
}